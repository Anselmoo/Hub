{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from io import BytesIO\n",
    "import os\n",
    "import posixpath\n",
    "from typing import Dict, Any\n",
    "import tensorflow as tf\n",
    "from fsspec import AbstractFileSystem\n",
    "from s3fs import S3FileSystem\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import hub\n",
    "from hub import schema\n",
    "from hub.utils import Timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LABELS = {\n",
    "    -1.0: \"uncertain\",\n",
    "    1.0: \"positive\",\n",
    "    0.0: \"negative\",\n",
    "    99.0: \"unmentioned\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_TEXT_LEN = 5000\n",
    "MEDIUM_TEXT_LEN = 25\n",
    "SMALL_TEXT_LEN = 8\n",
    "MY_LARGE_TEXT = schema.Text(max_shape=(LARGE_TEXT_LEN,), dtype=\"uint8\")\n",
    "MY_MEDIUM_TEXT = schema.Text(max_shape=(MEDIUM_TEXT_LEN,), dtype=\"uint8\")\n",
    "MY_SMALL_TEXT = schema.Text((SMALL_TEXT_LEN,), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MimiciiiCxr:\n",
    "    def __init__(self, image_size=512):\n",
    "        self._image_size = image_size\n",
    "\n",
    "    def _info(self):\n",
    "        image_size = self._image_size\n",
    "        MAX_IMAGE_COUNT = 4\n",
    "\n",
    "        return {\n",
    "            \"subject_id\": MY_SMALL_TEXT,\n",
    "            \"study_id\": MY_SMALL_TEXT,\n",
    "            \"study_date\": MY_SMALL_TEXT,\n",
    "            \"study_time\": MY_MEDIUM_TEXT,\n",
    "            \"report\": MY_LARGE_TEXT,\n",
    "            \"label_chexpert\": schema.ClassLabel(\n",
    "                shape=(14,), names=list(_LABELS.values())\n",
    "            ),\n",
    "            \"label_negbio\": schema.ClassLabel(\n",
    "                shape=(14,), names=list(_LABELS.values())\n",
    "            ),\n",
    "            \"image\": schema.Tensor(\n",
    "                shape=(None, image_size, image_size, 1),\n",
    "                max_shape=(MAX_IMAGE_COUNT, image_size, image_size, 1),\n",
    "                dtype=\"bool\",\n",
    "            ),\n",
    "            \"dicom_id\": MY_LARGE_TEXT,  # different ids not separated i.e a|b|c\n",
    "            \"columns\": schema.Tensor(max_shape=(MAX_IMAGE_COUNT,), dtype=\"int32\"),\n",
    "            \"rows\": schema.Tensor(max_shape=(MAX_IMAGE_COUNT,), dtype=\"int32\"),\n",
    "            \"viewPosition\": schema.ClassLabel(\n",
    "                shape=(None,),\n",
    "                max_shape=(MAX_IMAGE_COUNT,),\n",
    "                names=[\n",
    "                    \"nan\",\n",
    "                    \"AP LLD\",\n",
    "                    \"LL\",\n",
    "                    \"PA RLD\",\n",
    "                    \"LPO\",\n",
    "                    \"PA\",\n",
    "                    \"LAO\",\n",
    "                    \"AP AXIAL\",\n",
    "                    \"XTABLE LATERAL\",\n",
    "                    \"RAO\",\n",
    "                    \"AP RLD\",\n",
    "                    \"SWIMMERS\",\n",
    "                    \"AP\",\n",
    "                    \"LATERAL\",\n",
    "                    \"PA LLD\",\n",
    "                ],\n",
    "            ),\n",
    "            \"viewCodeSequence_CodeMeaning\": schema.ClassLabel(\n",
    "                shape=(None,),\n",
    "                max_shape=(MAX_IMAGE_COUNT,),\n",
    "                names=[\n",
    "                    \"Erect\",\n",
    "                    \"left lateral\",\n",
    "                    \"lateral\",\n",
    "                    \"postero-anterior\",\n",
    "                    \"nan\",\n",
    "                    \"Recumbent\",\n",
    "                    \"left anterior oblique\",\n",
    "                    \"antero-posterior\",\n",
    "                ],\n",
    "            ),\n",
    "            \"patientOrientationCodeSequence_CodeMeaning\": schema.ClassLabel(\n",
    "                shape=(None,),\n",
    "                max_shape=(MAX_IMAGE_COUNT,),\n",
    "                names=[\"Erect\", \"Recumbent\", \"nan\"],\n",
    "            ),\n",
    "            \"procedureCodeSequence_CodeMeaning\": schema.ClassLabel(\n",
    "                shape=(None,),\n",
    "                max_shape=(MAX_IMAGE_COUNT,),\n",
    "                names=[\n",
    "                    \"DX CHEST & RIBS\",\n",
    "                    \"CHEST (PORTABLE AP)\",\n",
    "                    \"DX CHEST PORT LINE/TUBE PLCMT 1 EXAM\",\n",
    "                    \"DX CHEST PORT LINE/TUBE PLCMT 2 EXAMS\",\n",
    "                    \"CHEST PRE-OP\",\n",
    "                    \"lateral\",\n",
    "                    \"CHEST (PA AND LAT)\",\n",
    "                    \"DX CHEST PORT LINE/TUBE PLCMT 3 EXAMS\",\n",
    "                    \"DX CHEST 2 VIEW PICC LINE PLACEMENT\",\n",
    "                    \"DX CHEST PORT LINE/TUBE PLCMT 5 EXAMS\",\n",
    "                    \"DX CHEST SGL VIEW PICC LINE PLACEMENT\",\n",
    "                    \"NEONATE CHEST & ABD TOGETHER PORTABLE LINE/TUBE PLCT 1 EXAM\",\n",
    "                    \"TRAUMA No.2 (AP CXR & PELVIS PORT)\",\n",
    "                    \"DX TRAUMA SERIES (PORTABLE)\",\n",
    "                    \"CHEST SGL VIEW/LINE PLACEMENT\",\n",
    "                    \"antero-posterior\",\n",
    "                    \"postero-anterior\",\n",
    "                    \"CHEST (SINGLE VIEW)\",\n",
    "                    \"CHEST PORT LINE PLACEMENT\",\n",
    "                    \"ABDOMEN (SUPINE ONLY)\",\n",
    "                    \"DX CHEST PORT LINE/TUBE PLCMT 4 EXAMS\",\n",
    "                    \"TRAUMA #3 (PORT CHEST ONLY)\",\n",
    "                    \"CHEST PORT LINE/TUBE PLCT 1 EXAM\",\n",
    "                    \"DX CHEST PORTABLE PICC LINE PLACEMENT\",\n",
    "                    \"CHEST (PRE-OP AP ONLY)\",\n",
    "                    \"DX CHEST WITH DECUB\",\n",
    "                    \"CHEST (PRE-OP PA & LAT)\",\n",
    "                ],\n",
    "            ),\n",
    "            \"performedProcedureStepDescription\": schema.ClassLabel(\n",
    "                shape=(None,),\n",
    "                max_shape=(MAX_IMAGE_COUNT,),\n",
    "                names=[\n",
    "                    \"CHEST SGL VIEW/LINE PLACEMENT PORT\",\n",
    "                    \"PORTABLE ABDOMEN\",\n",
    "                    \"RIB BILAT, W/AP CHEST PORT\",\n",
    "                    \"CHEST (SINGLE VIEW) PORT\",\n",
    "                    \"nan\",\n",
    "                    \"CHEST SGL VIEW/LINE PLACEMENT\",\n",
    "                    \"CHEST (PORTABLE AP) IN O.R.\",\n",
    "                    \"TRAUMA #2 (AP CXR AND PELVIS PORT)\",\n",
    "                    \"KNEE (AP, LAT AND TUNNEL) LEFT\",\n",
    "                    \"RIB BILAT, W/AP CHEST\",\n",
    "                    \"Portable Chest\",\n",
    "                    \"CHEST (PORTABLE AP) PORT\",\n",
    "                    \"CHEST (APICAL LORDOTIC ONLY) PORT\",\n",
    "                    \"RIB UNILAT, W/ AP CHEST LEFT\",\n",
    "                    \"ABDOMEN (SUPINE AND ERECT)\",\n",
    "                    \"TRAUMA #3 (PORT CHEST ONLY)\",\n",
    "                    \"RIB, UNILAT (NO CXR)\",\n",
    "                    \"CHEST (SINGLE VIEW)\",\n",
    "                    \"CHEST PORT LINE/TUBE PLCT 1 EXAM PORT\",\n",
    "                    \"ABD PORT LINE/TUBE PLACEMENT 1 EXAM PORT PORT\",\n",
    "                    \"BABYGRAM (CHEST ONLY)\",\n",
    "                    \"ABDOMEN (SUPINE ONLY)\",\n",
    "                    \"CHEST (PRE-OP PA AND LAT) PORT PORT\",\n",
    "                    \"DX CHEST 2 VIEW PICC LINE PLACEMENT\",\n",
    "                    \"ABDOMEN (SUPINE ONLY) PORT\",\n",
    "                    \"CHEST PORT LINE/TUBE PLCT 1 EXAM\",\n",
    "                    \"CHEST (PORTABLE AP)\",\n",
    "                    \"CHEST (PA AND LAT)\",\n",
    "                    \"ABDOMEN (SUPINE AND ERECT) PORT\",\n",
    "                    \"CHEST (PA AND LAT) PORT\",\n",
    "                    \"ABDOMEN (LAT DECUB ONLY) PORT LEFT\",\n",
    "                    \"CHEST (PA, LAT AND OBLIQUES)\",\n",
    "                    \"CHEST (PRE-OP PA AND LAT) PORT\",\n",
    "                    \"ABD PORT LINE/TUBE PLACEMENT 1 EXAM\",\n",
    "                    \"Performed Desc\",\n",
    "                    \"AP/PA SINGLE VIEW EXPIRATORY CHEST\",\n",
    "                    \"CHEST (BOTH OBLIQUES ONLY) PORT\",\n",
    "                    \"CHEST (PRE-OP PA AND LAT)\",\n",
    "                    \"DX CHEST PORT LINE/TUBE PLCMT 1 EXAM\",\n",
    "                    \"PELVIS (AP ONLY)\",\n",
    "                    \"CHEST (SINGLE VIEW) IN O.R.\",\n",
    "                    \"CHEST (PRE-OP AP ONLY)\",\n",
    "                    \"CHEST (LAT DECUB ONLY)\",\n",
    "                    \"CHEST PORT. LINE PLACEMENT\",\n",
    "                    \"DX CHEST PORTABLE PICC LINE PLACEMENT\",\n",
    "                    \"DX CHEST PORT LINE/TUBE PLCMT 3 EXAMS\",\n",
    "                    \"ABD PORT LINE/TUBE PLACEMENT 1 EXAM PORT\",\n",
    "                    \"CHEST (LAT DECUB ONLY) PORT\",\n",
    "                ],\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    def _intermitidate_schema(self):\n",
    "        return {\"row\": MY_LARGE_TEXT}\n",
    "\n",
    "    def _generate_dataset(\n",
    "        self,\n",
    "        filepath: str,\n",
    "        manual_dir: str,\n",
    "        fs: AbstractFileSystem,\n",
    "        output_dir: str,\n",
    "        scheduler,\n",
    "        workers,\n",
    "    ):\n",
    "        def _right_size(row):\n",
    "            row = row[\"row\"]\n",
    "            data = row.split(\",\")\n",
    "            if len(data) == 11:\n",
    "                return {\"row\": row}\n",
    "            else:\n",
    "                return []\n",
    "\n",
    "        image_size = self._image_size\n",
    "        result = fs.cat_file(os.path.join(manual_dir, \"mimic-cxr-2.0.0-chexpert.csv\"))\n",
    "        with BytesIO(result) as f:\n",
    "            chexpert_df = pd.read_csv(f)\n",
    "        result = fs.cat_file(os.path.join(manual_dir, \"mimic-cxr-2.0.0-negbio.csv\"))\n",
    "        with BytesIO(result) as f:\n",
    "            negbio_df = pd.read_csv(f)\n",
    "        chexpert_df = chexpert_df.fillna(99.0)\n",
    "        negbio_df = negbio_df.fillna(99.0)\n",
    "\n",
    "        def _check_files(row):\n",
    "            try:\n",
    "                row = row[\"row\"]\n",
    "                (\n",
    "                    study_id,\n",
    "                    subject_id,\n",
    "                    split,\n",
    "                    dicom_id,\n",
    "                    performedProcedureStepDescription,\n",
    "                    ViewPosition,\n",
    "                    StudyDate,\n",
    "                    StudyTime,\n",
    "                    procedureCodeSequence_CodeMeaning,\n",
    "                    ViewCodeSequence_CodeMeaning,\n",
    "                    patientOrientationCodeSequence_CodeMeaning,\n",
    "                ) = row.split(\",\")\n",
    "            except:\n",
    "                print(\"##########\", len(row.split(\",\")), row)\n",
    "                return []\n",
    "            basepath = \"{}/files/p{}/p{}/s{}\".format(\n",
    "                manual_dir, subject_id[0:2], subject_id, study_id\n",
    "            )\n",
    "            paths = [\"{}/{}.dcm\".format(basepath, d) for d in dicom_id.split(\"|\")]\n",
    "            paths.append(basepath + \".txt\")\n",
    "            for path in paths:\n",
    "                if not fs.exists(path):\n",
    "                    return []\n",
    "\n",
    "            # Job Graph Too Large\n",
    "\n",
    "            try:\n",
    "                negbio_values = negbio_df[\n",
    "                    (negbio_df[\"subject_id\"] == int(subject_id))\n",
    "                    & (negbio_df[\"study_id\"] == int(study_id))\n",
    "                ].values.tolist()[0][2:]\n",
    "                chexpert_values = chexpert_df[\n",
    "                    (chexpert_df[\"subject_id\"] == int(subject_id))\n",
    "                    & (chexpert_df[\"study_id\"] == int(study_id))\n",
    "                ].values.tolist()[0][2:]\n",
    "                negbio_values = [_LABELS[v] for v in negbio_values]\n",
    "                chexpert_values = [_LABELS[v] for v in chexpert_values]\n",
    "            except Exception as e:\n",
    "                print(subject_id)\n",
    "                print(study_id)\n",
    "                return []\n",
    "\n",
    "            return [{\"row\": row}]\n",
    "\n",
    "        def _process_example(row):\n",
    "            def fast_histogram_equalize(image):\n",
    "                \"\"\"histogram for integer based images\"\"\"\n",
    "                image = image - tf.reduce_min(image)\n",
    "                image = tf.cast(image, tf.int32)\n",
    "                histogram = tf.math.bincount(image)\n",
    "                cdf = tf.cast(tf.math.cumsum(histogram), tf.float32)\n",
    "                cdf = cdf / cdf[-1]\n",
    "                return tf.gather(params=cdf, indices=image)\n",
    "\n",
    "            row = row[\"row\"]\n",
    "            (\n",
    "                study_id,\n",
    "                subject_id,\n",
    "                split,\n",
    "                dicom_id,\n",
    "                performedProcedureStepDescription,\n",
    "                ViewPosition,\n",
    "                StudyDate,\n",
    "                StudyTime,\n",
    "                procedureCodeSequence_CodeMeaning,\n",
    "                ViewCodeSequence_CodeMeaning,\n",
    "                patientOrientationCodeSequence_CodeMeaning,\n",
    "            ) = row.split(\",\")\n",
    "\n",
    "            # Job Graph Too Large\n",
    "            result = fs.cat_file(\n",
    "                os.path.join(manual_dir, \"mimic-cxr-2.0.0-chexpert.csv\")\n",
    "            )\n",
    "            with BytesIO(result) as f:\n",
    "                chexpert_df = pd.read_csv(f)\n",
    "            result = fs.cat_file(os.path.join(manual_dir, \"mimic-cxr-2.0.0-negbio.csv\"))\n",
    "            with BytesIO(result) as f:\n",
    "                negbio_df = pd.read_csv(f)\n",
    "            chexpert_df = chexpert_df.fillna(99.0)\n",
    "            negbio_df = negbio_df.fillna(99.0)\n",
    "\n",
    "            dicom_id = dicom_id.split(\"|\")\n",
    "            ViewPosition = ViewPosition.split(\"|\")\n",
    "            ViewCodeSequence_CodeMeaning = ViewCodeSequence_CodeMeaning.split(\"|\")\n",
    "            patientOrientationCodeSequence_CodeMeaning = (\n",
    "                patientOrientationCodeSequence_CodeMeaning.split(\"|\")\n",
    "            )\n",
    "\n",
    "            # removing \\n\n",
    "            patientOrientationCodeSequence_CodeMeaning[\n",
    "                -1\n",
    "            ] = patientOrientationCodeSequence_CodeMeaning[-1][:-1]\n",
    "            procedureCodeSequence_CodeMeaning = procedureCodeSequence_CodeMeaning.split(\n",
    "                \"|\"\n",
    "            )\n",
    "            performedProcedureStepDescription = performedProcedureStepDescription.split(\n",
    "                \"|\"\n",
    "            )\n",
    "            basepath = \"{}/files/p{}/p{}/s{}\".format(\n",
    "                manual_dir, subject_id[0:2], subject_id, study_id\n",
    "            )\n",
    "\n",
    "            dicom_paths = [\"{}/{}.dcm\".format(basepath, d) for d in dicom_id]\n",
    "            images = []\n",
    "            rows = []\n",
    "            columns = []\n",
    "            for dicom_path in dicom_paths:\n",
    "                result = fs.cat_file(dicom_path)\n",
    "                with BytesIO(result) as d:\n",
    "                    ds = pydicom.dcmread(d)\n",
    "                    image = tf.squeeze(tf.constant(ds.pixel_array))[..., None]\n",
    "                    row, col, channel = image.shape\n",
    "                    image = fast_histogram_equalize(image)\n",
    "                    images.append(\n",
    "                        tf.cast(\n",
    "                            tf.round(\n",
    "                                tf.image.resize_with_pad(image, image_size, image_size)\n",
    "                            ),\n",
    "                            tf.uint16,\n",
    "                        ).numpy()\n",
    "                    )\n",
    "                    rows.append(row)\n",
    "                    columns.append(col)\n",
    "\n",
    "            negbio_values = negbio_df[\n",
    "                (negbio_df[\"subject_id\"] == int(subject_id))\n",
    "                & (negbio_df[\"study_id\"] == int(study_id))\n",
    "            ].values.tolist()[0][2:]\n",
    "            chexpert_values = chexpert_df[\n",
    "                (chexpert_df[\"subject_id\"] == int(subject_id))\n",
    "                & (chexpert_df[\"study_id\"] == int(study_id))\n",
    "            ].values.tolist()[0][2:]\n",
    "            negbio_values = [_LABELS[v] for v in negbio_values]\n",
    "            chexpert_values = [_LABELS[v] for v in chexpert_values]\n",
    "            if len(images) >= 5:\n",
    "                return []\n",
    "            images = np.array(images)\n",
    "            try:\n",
    "                return {\n",
    "                    \"subject_id\": subject_id,\n",
    "                    \"study_id\": study_id,\n",
    "                    \"study_date\": StudyDate.split(\"|\")[0],\n",
    "                    \"study_time\": StudyTime.split(\"|\")[0],\n",
    "                    \"report\": fs.cat_file(basepath + \".txt\").decode(\"utf-8\"),\n",
    "                    \"label_chexpert\": np.array(\n",
    "                        [\n",
    "                            schema_[\"label_chexpert\"].str2int(item)\n",
    "                            for item in chexpert_values\n",
    "                        ]\n",
    "                    ),\n",
    "                    \"label_negbio\": np.array(\n",
    "                        [\n",
    "                            schema_[\"label_negbio\"].str2int(item)\n",
    "                            for item in negbio_values\n",
    "                        ]\n",
    "                    ),\n",
    "                    \"image\": images,\n",
    "                    \"rows\": np.array(rows),\n",
    "                    \"columns\": np.array(columns),\n",
    "                    \"dicom_id\": \"|\".join(dicom_id),\n",
    "                    \"viewPosition\": np.array(\n",
    "                        [schema_[\"viewPosition\"].str2int(item) for item in ViewPosition]\n",
    "                    ),\n",
    "                    \"viewCodeSequence_CodeMeaning\": np.array(\n",
    "                        [\n",
    "                            schema_[\"viewCodeSequence_CodeMeaning\"].str2int(item)\n",
    "                            for item in ViewCodeSequence_CodeMeaning\n",
    "                        ]\n",
    "                    ),\n",
    "                    \"patientOrientationCodeSequence_CodeMeaning\": np.array(\n",
    "                        [\n",
    "                            schema_[\n",
    "                                \"patientOrientationCodeSequence_CodeMeaning\"\n",
    "                            ].str2int(item)\n",
    "                            for item in patientOrientationCodeSequence_CodeMeaning\n",
    "                        ]\n",
    "                    ),\n",
    "                    \"procedureCodeSequence_CodeMeaning\": np.array(\n",
    "                        [\n",
    "                            schema_[\"procedureCodeSequence_CodeMeaning\"].str2int(item)\n",
    "                            for item in procedureCodeSequence_CodeMeaning\n",
    "                        ]\n",
    "                    ),\n",
    "                    \"performedProcedureStepDescription\": np.array(\n",
    "                        [\n",
    "                            schema_[\"performedProcedureStepDescription\"].str2int(item)\n",
    "                            for item in performedProcedureStepDescription\n",
    "                        ]\n",
    "                    ),\n",
    "                }\n",
    "            except:\n",
    "                return []\n",
    "\n",
    "        result = fs.cat_file(filepath)\n",
    "        with BytesIO(result) as f:\n",
    "            lines = [{\"row\": line.decode(\"utf-8\")} for line in f.readlines()[1:]]\n",
    "\n",
    "        schema_ = self._info()\n",
    "        schemai = self._intermitidate_schema()\n",
    "        print(\"Number of samples: \", len(lines))\n",
    "        lines = lines[:1000] # comment this out to work on full dataset\n",
    "        with Timer(\"Total time\"):\n",
    "            with Timer(\"Time of first transform\"):\n",
    "                ds1 = hub.transform(\n",
    "                    schemai,\n",
    "                    scheduler=scheduler,\n",
    "                    workers=workers,\n",
    "                )(_right_size)(lines)\n",
    "                ds1 = ds1.store(f\"{output_dir}/ds1\")\n",
    "                print(\"LEN DS1:\", len(ds1))\n",
    "            with Timer(\"Time of second transform\"):\n",
    "                ds2 = hub.transform(\n",
    "                    schemai,\n",
    "                    scheduler=scheduler,\n",
    "                    workers=workers,\n",
    "                )(_check_files)(ds1)\n",
    "                ds2 = ds2.store(f\"{output_dir}/ds2\", sample_per_shard=400)\n",
    "                print(\"LEN DS2:\", len(ds2))\n",
    "            with Timer(\"Time of third transform\"):\n",
    "                ds3 = hub.transform(\n",
    "                    schema_,\n",
    "                    scheduler=scheduler,\n",
    "                    workers=workers,\n",
    "                )(_process_example)(ds2)\n",
    "                ds3.store(f\"{output_dir}/ds3\", sample_per_shard=400)\n",
    "        print(\"Success, number of elements for phase 3:\", len(ds3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_WORKERS = 10\n",
    "DEFAULT_SCHEDULER = \"single\"\n",
    "output_path= \"s3://snark-gradient-raw-data/sample_dataset_1000\"\n",
    "fs = S3FileSystem(default_block_size=2 ** 26)\n",
    "manual_dir = \"s3://snark-gradient-raw-data/mimic-cxr-2.0.0\"\n",
    "filepath = posixpath.join(manual_dir, \"train-split.csv\")\n",
    "cxr = MimiciiiCxr()\n",
    "cxr._generate_dataset(filepath, manual_dir, fs, output_path, DEFAULT_SCHEDULER, DEFAULT_WORKERS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}